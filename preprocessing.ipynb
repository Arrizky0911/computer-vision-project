{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "na1hJCOXd5yY",
        "outputId": "aa3eb738-6ec6-4056-cce4-22fb23f028a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/.shortcut-targets-by-id/1tnt3cKRdWn9lFKrM82KlrZH6CO5EgchD/Computer Vision Project/kits23\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "FOLDERNAME = \"Computer Vision Project/kits23\"\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
        "\n",
        "%cd /content/drive/My\\ Drive/$FOLDERNAME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciHOdIKq6oQk",
        "outputId": "f9f58713-c16b-4f0b-b086-06c17cfa4ee8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (5.3.2)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel) (6.5.2)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from nibabel) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.11/dist-packages (from nibabel) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.11/dist-packages (from nibabel) (4.12.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install nibabel\n",
        "\n",
        "import numpy as np\n",
        "from scipy.ndimage import zoom\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from os.path import join, dirname, basename, exists\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbH4OA6IMr65"
      },
      "outputs": [],
      "source": [
        "def calculate_intensity_stats(imaging_paths, segmentation_paths):\n",
        "    intensities = []\n",
        "\n",
        "    for img_path, seg_path in zip(imaging_paths, segmentation_paths):\n",
        "        img = nib.load(img_path).get_fdata()\n",
        "        seg = nib.load(seg_path).get_fdata()\n",
        "\n",
        "        # Extract foreground intensities\n",
        "        foreground = img[seg > 0]\n",
        "        intensities.extend(foreground)\n",
        "\n",
        "    intensities = np.array(intensities)\n",
        "\n",
        "    p_min = np.percentile(intensities, 0.5)\n",
        "    p_max = np.percentile(intensities, 99.5)\n",
        "    mean = np.mean(intensities)\n",
        "    std = np.std(intensities)\n",
        "\n",
        "    return p_min, p_max, mean, std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oixPIhGAOGSJ"
      },
      "outputs": [],
      "source": [
        "p_min, p_max, mean, std = calculate_intensity_stats(imaging_paths, segmentation_paths)\n",
        "\n",
        "print(f\"p_min: {p_min}\")\n",
        "print(f\"p_max: {p_max}\")\n",
        "print(f\"Mean: {mean}\")\n",
        "print(f\"Standard Deviation: {std}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sm2EV3csx48"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('../dataset.csv')\n",
        "df = df[df['split'] == 'train']\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"label_column\"] if \"label_column\" in df.columns else None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlYchTYTDr9h"
      },
      "outputs": [],
      "source": [
        "csv_path = '../dataset.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "train_df = df[df['split'] == 'train']\n",
        "val_df = df[df['split'] == 'val']\n",
        "test_df = df[df['split'] == 'test']\n",
        "\n",
        "# preprocessed_train_df = pd.read_csv('../preprocessed_train.csv')\n",
        "# preprocessed_val_df = pd.read_csv('../preprocessed_val.csv')\n",
        "# preprocessed_test_df = pd.read_csv('../preprocessed_test.csv')\n",
        "\n",
        "# imaging_paths_train = train_df[~train_df['segment_path'].apply(lambda x: x.split('/')[1]).isin(preprocessed_train_df['case'])]['image'].tolist()\n",
        "# segmentation_paths_train = train_df[~train_df['segment_path'].apply(lambda x: x.split('/')[1]).isin(preprocessed_train_df['case'])]['label'].tolist()\n",
        "imaging_paths_train = train_df['image_path'].tolist()\n",
        "segmentation_paths_train = train_df['segment_path'].tolist()\n",
        "imaging_paths_train = imaging_paths_train[:60]\n",
        "segmentation_paths_train = segmentation_paths_train[:60]\n",
        "\n",
        "# imaging_paths_val = val_df[~val_df['segment_path'].apply(lambda x: x.split('/')[1]).isin(preprocessed_val_df['case'])]['image'].tolist()\n",
        "# segmentation_paths_val = val_df[~val_df['segment_path'].apply(lambda x: x.split('/')[1]).isin(preprocessed_val_df['case'])]['label'].tolist()\n",
        "imaging_paths_val = val_df['image_path'].tolist()\n",
        "segmentation_paths_val = val_df['segment_path'].tolist()\n",
        "\n",
        "# imaging_paths_test = test_df[~test_df['segment_path'].apply(lambda x: x.split('/')[1]).isin(preprocessed_test_df['case'])]['image'].tolist()\n",
        "# segmentation_paths_test = test_df[~test_df['segment_path'].apply(lambda x: x.split('/')[1]).isin(preprocessed_test_df['case'])]['label'].tolist()\n",
        "imaging_paths_test = test_df['image_path'].tolist()\n",
        "segmentation_paths_test = test_df['segment_path'].tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMU7Pv8LMDcu",
        "outputId": "0f15b011-94f4-4fa6-ab6c-8ef7d9baf202"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60\n",
            "60\n",
            "['dataset/case_00108/imaging.nii.gz', 'dataset/case_00581/imaging.nii.gz']\n",
            "['dataset/case_00108/segmentation.nii.gz', 'dataset/case_00581/segmentation.nii.gz']\n"
          ]
        }
      ],
      "source": [
        "print(len(imaging_paths_train))\n",
        "print(len(segmentation_paths_train))\n",
        "print(imaging_paths_train[:2])\n",
        "print(segmentation_paths_train[:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWe-94DKOaW2",
        "outputId": "0f8f8cb5-af1d-43f2-da95-7ee4cede0c03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79\n",
            "79\n",
            "['dataset/case_00449/imaging.nii.gz', 'dataset/case_00446/imaging.nii.gz']\n",
            "['dataset/case_00449/segmentation.nii.gz', 'dataset/case_00446/segmentation.nii.gz']\n"
          ]
        }
      ],
      "source": [
        "print(len(imaging_paths_val))\n",
        "print(len(segmentation_paths_val))\n",
        "print(imaging_paths_val[:2])\n",
        "print(segmentation_paths_val[:2])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IC_QLwkOfwg",
        "outputId": "d645371d-e68f-4f48-e478-ec99959379e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98\n",
            "98\n",
            "['dataset/case_00551/imaging.nii.gz', 'dataset/case_00084/imaging.nii.gz', 'dataset/case_00534/imaging.nii.gz', 'dataset/case_00572/imaging.nii.gz', 'dataset/case_00528/imaging.nii.gz']\n",
            "['dataset/case_00551/segmentation.nii.gz', 'dataset/case_00084/segmentation.nii.gz', 'dataset/case_00534/segmentation.nii.gz', 'dataset/case_00572/segmentation.nii.gz', 'dataset/case_00528/segmentation.nii.gz']\n"
          ]
        }
      ],
      "source": [
        "print(len(imaging_paths_test))\n",
        "print(len(segmentation_paths_test))\n",
        "print(imaging_paths_test[:5])\n",
        "print(segmentation_paths_test[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PLWqGhyeBDe"
      },
      "outputs": [],
      "source": [
        "def load_ct_image(file_path):\n",
        "    image = nib.load(file_path)\n",
        "    ct_array = image.get_fdata()\n",
        "    spacing = image.header.get_zooms()[:3]\n",
        "    return ct_array, spacing\n",
        "\n",
        "def resample_image(image, original_spacing, target_spacing):\n",
        "    resize_factors = [os / ts for os, ts in zip(original_spacing, target_spacing)]\n",
        "    return zoom(image, resize_factors, order=3)  # Cubic interpolation\n",
        "\n",
        "def resample_segmentation(segmentation, original_spacing, target_spacing):\n",
        "    resize_factors = [os / ts for os, ts in zip(original_spacing, target_spacing)]\n",
        "    return zoom(segmentation, resize_factors, order=0)  # Nearest neighbor interpolation\n",
        "\n",
        "def crop_to_nonzero(image, segmentation):\n",
        "    nonzero_coords = np.argwhere(image > 0)\n",
        "    min_coords = nonzero_coords.min(axis=0)\n",
        "    max_coords = nonzero_coords.max(axis=0) + 1\n",
        "\n",
        "    cropped_image = image[min_coords[0]:max_coords[0],\n",
        "                          min_coords[1]:max_coords[1],\n",
        "                          min_coords[2]:max_coords[2]]\n",
        "    cropped_segmentation = segmentation[min_coords[0]:max_coords[0],\n",
        "                                        min_coords[1]:max_coords[1],\n",
        "                                        min_coords[2]:max_coords[2]]\n",
        "    return cropped_image, cropped_segmentation\n",
        "\n",
        "def ct_normalize(image, clip_range=(-61, 305), mean=103, std=75.17):\n",
        "    image = np.clip(image, clip_range[0], clip_range[1])\n",
        "    normalized_image = (image - mean) / std\n",
        "    return normalized_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyXMBFECexx1"
      },
      "outputs": [],
      "source": [
        "def extract_random_patches(image, segment, patch_size=(128, 128, 128), num_patches=10, foreground_ratio=0.4):\n",
        "    patches = []\n",
        "    ground_truths = []\n",
        "    x_max, y_max, z_max = image.shape\n",
        "    x_patch, y_patch, z_patch = patch_size\n",
        "\n",
        "    num_foreground_patches = int(num_patches * foreground_ratio)\n",
        "    num_background_patches = num_patches - num_foreground_patches\n",
        "\n",
        "    foreground_indices = np.argwhere(segment >= 2)\n",
        "    while len(patches) < num_foreground_patches and len(foreground_indices) > 0:\n",
        "        idx = np.random.randint(0, len(foreground_indices))\n",
        "        x, y, z = foreground_indices[idx]\n",
        "\n",
        "        # Define the patch start and end coordinates\n",
        "        x_start = max(0, x - x_patch // 2)\n",
        "        y_start = max(0, y - y_patch // 2)\n",
        "        z_start = max(0, z - z_patch // 2)\n",
        "        x_end = min(x_start + x_patch, x_max)\n",
        "        y_end = min(y_start + y_patch, y_max)\n",
        "        z_end = min(z_start + z_patch, z_max)\n",
        "\n",
        "        # Adjust start coordinates if the patch size is out of bounds\n",
        "        x_start = x_end - x_patch if x_end - x_start < x_patch else x_start\n",
        "        y_start = y_end - y_patch if y_end - y_start < y_patch else y_start\n",
        "        z_start = z_end - z_patch if z_end - z_start < z_patch else z_start\n",
        "\n",
        "        patch = image[x_start:x_end, y_start:y_end, z_start:z_end]\n",
        "        ground_truth = segment[x_start:x_end, y_start:y_end, z_start:z_end]\n",
        "\n",
        "        if patch.shape == patch_size and ground_truth.shape == patch_size:\n",
        "            patches.append(patch)\n",
        "            ground_truths.append(ground_truth)\n",
        "\n",
        "    while len(patches) < num_patches:\n",
        "        x = np.random.randint(0, max(x_max - x_patch, 1))\n",
        "        y = np.random.randint(0, max(y_max - y_patch, 1))\n",
        "        z = np.random.randint(0, max(z_max - z_patch, 1))\n",
        "        patch = image[x:x + x_patch, y:y + y_patch, z:z + z_patch]\n",
        "        ground_truth = segment[x:x + x_patch, y:y + y_patch, z:z + z_patch]\n",
        "\n",
        "        # Ensure the patch does not contain foreground voxels\n",
        "        if patch.shape == patch_size and ground_truth.shape == patch_size:\n",
        "            patches.append(patch)\n",
        "            ground_truths.append(ground_truth)\n",
        "\n",
        "    return patches, ground_truths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "355izRSbdoMT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def preprocessed_to_tensor(image, label):\n",
        "    image_tensor = torch.tensor(image, dtype=torch.float32).unsqueeze(0)\n",
        "    label_tensor = torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "    return image_tensor, label_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-A35ur8ZQ8n"
      },
      "outputs": [],
      "source": [
        "def preprocess_to_patches(image, segmentation, patch_size, num_patches, output_data_dir, output_label_dir, csv_path, case_id, df):\n",
        "    image_patches, segmentation_patches = extract_random_patches(image, segmentation, patch_size, num_patches)\n",
        "\n",
        "    for i, (img_patch, seg_patch) in enumerate(zip(image_patches, segmentation_patches)):\n",
        "        img_patch, seg_patch = preprocessed_to_tensor(img_patch, seg_patch)\n",
        "        output_data_path = os.path.join(output_data_dir, f\"image_{case_id}_{i}.pth\")\n",
        "        output_label_path = os.path.join(output_label_dir, f\"segment_{case_id}_{i}.pth\")\n",
        "        df = pd.concat([df, pd.DataFrame({'image': [output_data_path], 'label': [output_label_path], 'case': [case_id]})], ignore_index=True)\n",
        "        torch.save(img_patch, output_data_path)\n",
        "        torch.save(seg_patch, output_label_path)\n",
        "\n",
        "    df.to_csv(csv_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SGgaZqLPrg4"
      },
      "outputs": [],
      "source": [
        "def preprocess(file_paths, seg_paths, train, target_spacing, output_data_dir, output_label_dir, csv_path):\n",
        "    if not exists(output_data_dir):\n",
        "            os.makedirs(output_data_dir)\n",
        "    if not exists(output_label_dir):\n",
        "            os.makedirs(output_label_dir)\n",
        "\n",
        "    if not exists(csv_path):\n",
        "        df = pd.DataFrame(columns=['image', 'label', 'case'])\n",
        "    else:\n",
        "        df = pd.read_csv(csv_path)\n",
        "\n",
        "    for idx, (ct_path, seg_path) in enumerate(tqdm(zip(file_paths, seg_paths))):\n",
        "        ct_array, original_spacing = load_ct_image(ct_path)\n",
        "        segmentation, _ = load_ct_image(seg_path)\n",
        "        case_id = ct_path.split('/')[1]\n",
        "\n",
        "        # Resample image and segmentation\n",
        "        resampled_image = resample_image(ct_array, original_spacing, target_spacing)\n",
        "        resampled_segmentation = resample_segmentation(segmentation, original_spacing, target_spacing)\n",
        "\n",
        "        # Normalize the image\n",
        "        normalized_image = ct_normalize(resampled_image)\n",
        "\n",
        "        if train:\n",
        "          preprocess_to_patches(normalized_image, resampled_segmentation, (128, 128, 128), 10, output_data_dir, output_label_dir, csv_path, case_id, df)\n",
        "        else:\n",
        "          # Convert To Tensor\n",
        "          normalized_image, resampled_segmentation = preprocessed_to_tensor(normalized_image, resampled_segmentation)\n",
        "\n",
        "          # Save the images\n",
        "          output_data_path = os.path.join(output_data_dir, f\"image_{case_id}.pth\")\n",
        "          output_label_path = os.path.join(output_label_dir, f\"segment_{case_id}.pth\")\n",
        "          df = pd.concat([df, pd.DataFrame({'image': [output_data_path], 'label': [output_label_path], 'case': [case_id]})], ignore_index=True)\n",
        "          torch.save(normalized_image, output_data_path)\n",
        "          torch.save(resampled_segmentation, output_label_path)\n",
        "          df.to_csv(csv_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2DWkCD7nR1Y",
        "outputId": "1eecef11-6fe5-4165-f6fd-218607e8a295"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "60it [1:20:44, 80.74s/it]\n"
          ]
        }
      ],
      "source": [
        "preprocess(\n",
        "    imaging_paths_train,\n",
        "    segmentation_paths_train,\n",
        "    train=True,\n",
        "    target_spacing=(0.78, 0.78, 1.0),\n",
        "    output_data_dir='../preprocessed_image_train_2nd',\n",
        "    output_label_dir='../preprocessed_segment_train_2nd',\n",
        "    csv_path='../preprocessed_train_1.csv',\n",
        "    )\n",
        "\n",
        "# preprocess(\n",
        "#     imaging_paths_train,\n",
        "#     segmentation_paths_train,\n",
        "#     train=True,\n",
        "#     target_spacing=(0.78, 0.78, 1.0),\n",
        "#     output_data_dir='../preprocessed_image_train',\n",
        "#     output_label_dir='../preprocessed_segment_train',\n",
        "#     csv_path='../preprocessed_train_2.csv',\n",
        "#     )\n",
        "\n",
        "# preprocess(\n",
        "#     imaging_paths_train,\n",
        "#     segmentation_paths_train,\n",
        "#     train=True,\n",
        "#     target_spacing=(0.78, 0.78, 1.0),\n",
        "#     output_data_dir='../preprocessed_image_train',\n",
        "#     output_label_dir='../preprocessed_segment_train',\n",
        "#     csv_path='../preprocessed_train_3.csv',\n",
        "#     )\n",
        "\n",
        "# preprocess(\n",
        "#     imaging_paths_val,\n",
        "#     segmentation_paths_val,\n",
        "#     train=False,\n",
        "#     target_spacing=(0.78, 0.78, 1.0),\n",
        "#     output_data_dir='../preprocessed_image_val',\n",
        "#     output_label_dir='../preprocessed_segment_val',\n",
        "#     csv_path='../preprocessed_val.csv',\n",
        "#     )\n",
        "# preprocess(\n",
        "#     imaging_paths_test,\n",
        "#     segmentation_paths_test,\n",
        "#     train=False,\n",
        "#     target_spacing=(0.78, 0.78, 1.0),\n",
        "#     output_data_dir='../preprocessed_image_test',\n",
        "#     output_label_dir='../preprocessed_segment_test',\n",
        "#     csv_path='../preprocessed_test.csv',\n",
        "#     )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}